{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "yee7ldp4w3vafimjm27m",
   "authorId": "5526226532556",
   "authorName": "DNAINTEGRASI",
   "authorEmail": "dna.dataintegrasi@gmail.com",
   "sessionId": "d295c1bc-12a8-4289-86fa-5a5108046d18",
   "lastEditTime": 1761636662283
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495e9c0b-0b57-43b9-ab44-9539a9007989",
   "metadata": {
    "name": "title",
    "collapsed": false
   },
   "source": "# **TELCO CHURN ANALYSIS**\n\nA telecommunications company aims to analyze customer behavior to identify those with a high likelihood of long-term retention. However, with the rapidly evolving telecommunications landscape, customers are constantly seeking the best services to meet their daily needs. To ensure sustained growth and competitiveness, the company must analyze potential customers before onboarding them, allowing for more targeted strategies that promote long-term loyalty.\n\n**Main Objectives:**\n1. Provide characteristics on churning customers\n2. Deliver data to further increase efficiency on marketing costs\n\nIn this case, leveraging a classification model would be the best option, where the output would either be a 'Yes' or 'No' option. Which meant the use of a **`confussion matrix`** to further enhance the scoring of the model. However there a few drawbacks in using a confussion matrix, which are:\n- **False Positive (FP)**: predicted as churn, actual stayed\n    1. Due to the prediction of churning, customers who are predicted to churn are given special benefits in order to prevent them from churning.\n    2. Customers are given special promotions (such as discount, special prices for subscription, bundling, etc.), however the customer stayed, therefore those promotions are considered ineffective.\n- **False Negative (FN)**: predicted as stayed, actual churn\n    1. Due to the prediction of not churning, customers who are predicted to not churn at all are not given any special treatment.\n    2. In order to maintain and increase company revenue, customers who churn needed to be replaced as soon as possible whereas the fee needed to obtain new customers are much higher than maintaning existing customers.\n\nFrom the consequences above, it is concluded that the loss suffered will be greater whenever the prediction predicted the customer as a non churning customer, but the actual customer is a churning customer. Therefore the value of **`False Negatives`** are needed to be pressed down, which in this case will be using **`f2 score`**.\n\n---"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "libraries"
   },
   "source": "import pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\n#visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#map\nimport folium\nfrom folium.plugins import MarkerCluster\nfrom IPython.display import display\n\n# train test split\nfrom sklearn.model_selection import train_test_split\n\n# encoding\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom category_encoders import OrdinalEncoder, BinaryEncoder\n\n# scaling\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler \n\n# column transformer & pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.pipeline import Pipeline\n\n# cross validation\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n\n# imbalance\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler, NearMiss\n\n# algorithm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# ensemble similar type\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier              # Bagging\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier         # Boosting\n\nfrom xgboost.sklearn import XGBClassifier\n\n# metric\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer, fbeta_score\n\n# model results\nfrom sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n\n# export model\nimport pickle\nimport joblib\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "churn_data"
   },
   "source": "WITH MAX_DATE AS (\n    SELECT \n        MAX(TO_DATE(_FIVETRAN_SYNCED)) AS max_date\n    FROM TELCO.RAW.TB_R_CHURN\n)\nSELECT \n    a.CUSTOMER_ID\n    ,a.GENDER\n    ,a.BIRTH_DATE\n    ,a.SENIOR_CITIZEN\n    ,a.PARTNER\n    ,a.DEPENDENTS\n    ,a.COUNTRY_CODE\n    ,a.STATE\n    ,a.CITY\n    ,a.ZIP_CODE\n    ,a.LATITUDE\n    ,a.LONGITUDE\n    ,a.PHONE_SERVICE\n    ,a.MULTIPLE_LINES\n    ,a.INTERNET_SERVICE\n    ,a.ONLINE_SECURITY\n    ,a.ONLINE_BACKUP\n    ,a.DEVICE_PROTECTION\n    ,a.TECH_SUPPORT\n    ,a.STREAMING_TV\n    ,a.STREAMING_MOVIES\n    ,a.CONTRACT\n    ,a.PAPERLESS_BILLING\n    ,a.PAYMENT_METHOD\n    ,a.DATE_JOINED\n    ,a.QUARTER\n    ,DATEDIFF('month', a.DATE_JOINED, CURRENT_DATE) AS TENURE_MONTHS\n    ,a.MONTHLY_CHARGES\n    ,(DATEDIFF('month', a.DATE_JOINED, CURRENT_DATE) * a.MONTHLY_CHARGES) AS TOTAL_CHARGES\n    ,CASE \n        WHEN DATEDIFF('year', a.DATE_JOINED, CURRENT_DATE) <= 1 THEN (DATEDIFF('month', a.DATE_JOINED, CURRENT_DATE) * a.MONTHLY_CHARGES) * 1\n        ELSE DATEDIFF('year', a.DATE_JOINED, CURRENT_DATE) * (DATEDIFF('month', a.DATE_JOINED, CURRENT_DATE) * a.MONTHLY_CHARGES)\n    END AS CLTV\n    ,a.CHURN_LABEL\n    ,a.CHURN_REASON\nFROM \n    TELCO.RAW.TB_R_CHURN a\nLEFT JOIN MAX_DATE b ON TO_DATE(a._FIVETRAN_SYNCED) = b.max_date\nWHERE b.max_date IS NOT NULL",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "data_analysis"
   },
   "source": "df = churn_data.to_pandas()\n\ncat_columns = df.describe(include= 'object').columns\nnum_columns = df.describe().columns\nplt.figure(figsize=(20,20))\ncount = 1\n\nfor _ in df.columns:\n    if _ in ['CUSTOMER_ID', 'BIRTH_DATE', 'COUNTRY_CODE', 'ZIP_CODE', 'LATITUDE', 'LONGITUDE', 'DATE_JOINED', 'CHURN_REASON']:\n        continue\n\n    elif _ in cat_columns:\n        plt.subplot(6, 5, count)\n        sns.histplot(data= df, x= _, hue= 'CHURN_LABEL')\n        plt.xlabel(None)\n\n        plt.title(_)\n        plt.xticks(rotation= 90, size= 8)\n        plt.tight_layout()\n        count = count + 1\n\n    else:\n        plt.subplot(6, 5, count)\n        sns.violinplot(data= df, x= 'CHURN_LABEL', y= _)\n        plt.xlabel(None)\n\n        plt.title(_)\n        plt.xticks(rotation= 90, size= 8)\n        plt.tight_layout()\n        count = count + 1\n;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f5810b76-dadc-466e-a853-68d8f75eaf5a",
   "metadata": {
    "language": "python",
    "name": "data_cleansing"
   },
   "outputs": [],
   "source": "df['BIRTH_DATE'] = pd.to_datetime(df['BIRTH_DATE'], errors='coerce')\n\ndf['BIRTH_YEAR'] = df['BIRTH_DATE'].dt.year\ndf['BIRTH_MONTH'] = df['BIRTH_DATE'].dt.month\ndf['BIRTH_DAY'] = df['BIRTH_DATE'].dt.day\n\ndf = df.drop(columns=['CUSTOMER_ID', 'DATE_JOINED', 'BIRTH_DATE', 'ZIP_CODE', 'CHURN_REASON'])\ndf.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8597ad67-9308-4ddb-9d33-a80c8b4eb88e",
   "metadata": {
    "language": "python",
    "name": "define_X_and_y"
   },
   "outputs": [],
   "source": "df['CHURN_LABEL'] = np.where(df['CHURN_LABEL'] == 'Yes', 1, 0)\n\nX = df.drop(columns= 'CHURN_LABEL')\ny = df['CHURN_LABEL']",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b4ad39c-b924-47b2-9dc0-66491b8288ae",
   "metadata": {
    "language": "python",
    "name": "train_test_split"
   },
   "outputs": [],
   "source": "(X_train, X_test, y_train, y_test) = train_test_split(\n    X,\n    y,\n    stratify= y,\n    random_state= 0,\n    test_size= 0.3\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2a67da0-14a8-4367-b420-ad57029d62e4",
   "metadata": {
    "language": "python",
    "name": "data_preprocessing"
   },
   "outputs": [],
   "source": "transformer = ColumnTransformer([\n    ('onehot', OneHotEncoder(drop= 'first'), [\n        'GENDER', 'SENIOR_CITIZEN', 'PARTNER', 'DEPENDENTS', 'COUNTRY_CODE', 'PHONE_SERVICE', 'MULTIPLE_LINES', 'INTERNET_SERVICE', 'ONLINE_SECURITY', 'ONLINE_BACKUP', 'DEVICE_PROTECTION', 'TECH_SUPPORT', 'STREAMING_TV', 'STREAMING_MOVIES', 'CONTRACT', 'PAPERLESS_BILLING', 'PAYMENT_METHOD'\n    ]),\n    ('binary', BinaryEncoder(), [\n        'STATE', 'CITY', 'QUARTER'\n    ]),\n    ('robust', RobustScaler(), [\n        'LATITUDE', 'LONGITUDE', 'TENURE_MONTHS', 'MONTHLY_CHARGES', 'TOTAL_CHARGES', 'CLTV', 'BIRTH_YEAR', 'BIRTH_MONTH', 'BIRTH_DAY'\n    ])\n], remainder= 'passthrough')\n\ntransformer.fit(X_train)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e29f1c76-af46-4b78-8c27-4bf745dabeae",
   "metadata": {
    "language": "python",
    "name": "cross_val"
   },
   "outputs": [],
   "source": "logreg = LogisticRegression(random_state=0, max_iter= 1000)\nknn = KNeighborsClassifier(n_neighbors=5)\ntree = DecisionTreeClassifier(max_depth=5, random_state=0)\n\nrandforest = RandomForestClassifier(random_state=0)\nbagging = BaggingClassifier(random_state=0, estimator= KNeighborsClassifier(n_neighbors= 3))\n\nadaboost = AdaBoostClassifier(random_state=0)\ngboost = GradientBoostingClassifier(random_state= 0)\nxgboost = XGBClassifier(random_state= 0)\n\nresampling = RandomOverSampler(random_state=0)\nf2 = make_scorer(fbeta_score, beta=2)\nlist_algo = [logreg, knn, tree, randforest, bagging, adaboost, gboost, xgboost]\n\nlist_mean_f2 = []\nlist_std_f2 = []\n\nfor _ in list_algo:\n    pipe_model = Pipeline([\n    ('resampling', resampling),\n    ('preprocessing', transformer),\n    ('modeling', _)\n    ])\n\n    cv_score_best_algo = cross_val_score(\n        estimator= pipe_model,\n        X= X_train,\n        y= y_train,\n        cv= 5,\n        scoring= f2\n    ).round(2)\n    \n    list_mean_f2.append(cv_score_best_algo.mean().round(3))\n    list_std_f2.append(cv_score_best_algo.std().round(3))\n\ndf_cv = pd.DataFrame()\ndf_cv['algo'] = list_algo\ndf_cv['mean_f2'] = list_mean_f2\ndf_cv['std_f2'] = list_std_f2\n\ndf_cv.sort_values(by= ['mean_f2', 'std_f2'], ascending= [False, True])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bfd9b296-afa3-4c6e-9122-db495fd06b40",
   "metadata": {
    "language": "python",
    "name": "hyperparameter_tuning"
   },
   "outputs": [],
   "source": "list_resampling = [RandomOverSampler(random_state=0), RandomUnderSampler(random_state=0), SMOTE(random_state=0), NearMiss(), None]\n\nmodel_pipe_best = Pipeline([\n    ('resampling', resampling),\n    ('prep', transformer),\n    ('modeling', tree)\n])\n\nhyperparam_tree = {\n    'resampling' : list_resampling,\n\n    'prep__robust' : [RobustScaler(), MinMaxScaler(), StandardScaler()],\n\n    'modeling__max_depth': [3, 5, 7, 10],                    # tree depth\n    'modeling__min_samples_split': [5, 10, 20, 30],          # minimum samples to split a node\n    'modeling__min_samples_leaf': [1, 2, 4, 6],              # minimum samples at leaf node\n}\n\ngridsearch_tree = GridSearchCV(\n    estimator= model_pipe_best,\n    param_grid= hyperparam_tree,\n    cv= 5,\n    scoring= f2,\n    n_jobs= 1\n)\n\ngridsearch_tree.fit(X_train, y_train)\ngridsearch_tree.best_score_",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49780765-9d91-4185-a872-fe7b81426f8a",
   "metadata": {
    "language": "python",
    "name": "predict_to_test_set"
   },
   "outputs": [],
   "source": "pipe_model_tree = Pipeline([\n        ('preprocessing', transformer),\n        ('modeling', tree)\n    ])\n\n# Model training\npipe_model_tree.fit(X_train, y_train)\n\n# Model predicting test set  \ny_pred_untuned = pipe_model_tree.predict(X_test)\n\nbest_model = gridsearch_tree.best_estimator_\n\n# Model training\nbest_model.fit(X_train, y_train)\n\n# Model predicting test set  \ny_pred_tuned = best_model.predict(X_test)\n\nprint(f'''{fbeta_score(y_test, y_pred_untuned, beta= 2)} - Before Tuning.\n{fbeta_score(y_test, y_pred_tuned, beta= 2)} - After Tuning.''')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34c0d28e-eda1-4005-b1f9-6bd9220d448d",
   "metadata": {
    "language": "python",
    "name": "confusion_matrix"
   },
   "outputs": [],
   "source": "plt.figure(figsize=(20,4))\n\nplt.subplot(1,4,2)\nsns.heatmap(data= confusion_matrix(y_test, y_pred_untuned), annot= True, fmt= 'g')\nplt.title('Before Tuning')\nplt.ylabel('Actual')\nplt.xlabel('Predict')\n\nplt.subplot(1,4,3)\nsns.heatmap(data= confusion_matrix(y_test, y_pred_tuned), annot= True, fmt= 'g')\nplt.title('After Tuning')\nplt.ylabel('Actual')\nplt.xlabel('Predict')\n\nplt.tight_layout()\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f57fa502-db55-4be9-848a-22ec69415e4f",
   "metadata": {
    "language": "python",
    "name": "export_model_to_stage",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "best_model.fit(X, y)\njoblib.dump(best_model, \"/tmp/churn_status_best_model.sav\")\n\nsession.file.put(\"/tmp/churn_status_best_model.sav\", \"@TELCO.RAW.ML_MODEL\", auto_compress=False, overwrite=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc249328-3faa-49cb-9b18-f61e461a7f07",
   "metadata": {
    "language": "sql",
    "name": "status_prediction"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE PROCEDURE TELCO.DATAMART.SP_CUSTOMER_STATUS_PREDICTION()\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.9'\nPACKAGES = ('pandas', 'scikit-learn', 'joblib', 'snowflake-snowpark-python', 'imbalanced-learn', 'category_encoders')\nHANDLER = 'main'\nAS\n$$\nimport pandas as pd\nimport joblib\nfrom snowflake.snowpark import Session\n\ndef main(session: Session) -> str:\n    query = \"\"\"\n        WITH MAX_DATE AS (\n            SELECT \n                MAX(TO_DATE(_FIVETRAN_SYNCED)) AS max_date\n            FROM TELCO.RAW.TB_R_CHURN\n        )\n        SELECT \n            a.CUSTOMER_ID\n            ,a.GENDER\n            ,a.BIRTH_DATE\n            ,a.SENIOR_CITIZEN\n            ,a.PARTNER\n            ,a.DEPENDENTS\n            ,a.COUNTRY_CODE\n            ,a.STATE\n            ,a.CITY\n            ,a.ZIP_CODE\n            ,a.LATITUDE\n            ,a.LONGITUDE\n            ,a.PHONE_SERVICE\n            ,a.MULTIPLE_LINES\n            ,a.INTERNET_SERVICE\n            ,a.ONLINE_SECURITY\n            ,a.ONLINE_BACKUP\n            ,a.DEVICE_PROTECTION\n            ,a.TECH_SUPPORT\n            ,a.STREAMING_TV\n            ,a.STREAMING_MOVIES\n            ,a.CONTRACT\n            ,a.PAPERLESS_BILLING\n            ,a.PAYMENT_METHOD\n            ,a.DATE_JOINED\n            ,a.QUARTER\n            ,a.TENURE_MONTHS\n            ,a.MONTHLY_CHARGES\n            ,a.TOTAL_CHARGES\n            ,a.CLTV\n            ,a.CHURN_REASON\n        FROM \n            TELCO.RAW.TB_R_CHURN a\n        LEFT JOIN MAX_DATE b ON TO_DATE(a._FIVETRAN_SYNCED) = b.max_date\n        WHERE b.max_date IS NOT NULL\n    \"\"\"\n    df_main = session.sql(query).to_pandas()\n    df_new = df_main.copy()\n    df_new['BIRTH_YEAR'] = df_new['BIRTH_DATE'].dt.year\n    df_new['BIRTH_MONTH'] = df_new['BIRTH_DATE'].dt.month\n    df_new['BIRTH_DAY'] = df_new['BIRTH_DATE'].dt.day\n    df_new = df_new.drop(columns=['CUSTOMER_ID', 'DATE_JOINED', 'BIRTH_DATE', 'ZIP_CODE', 'CHURN_REASON'])\n\n    # 2️⃣ Load model from stage\n    model_path = \"@TELCO.RAW.ML_MODEL/churn_status_best_model.sav\"\n    session.file.get(model_path, \"/tmp\")  # downloads to /tmp inside Snowflake runtime\n    model = joblib.load(\"/tmp/churn_status_best_model.sav\")\n\n    # 3️⃣ Predict\n    df_new[\"PREDICTED_STATUS\"] = model.predict(df_new)\n    df_new[\"PREDICTED_STATUS\"] = df_new[\"PREDICTED_STATUS\"].replace({1: \"Yes\", 0: \"No\"})\n    \n    df_new[\"PREDICTION_DATE\"] = session.sql(\"SELECT CURRENT_DATE()\").collect()[0][0]\n    df_export = pd.DataFrame()\n    df_export['CUSTOMER_ID'] = df_main['CUSTOMER_ID']\n    df_export['PREDICTION_RESULTS'] = df_new['PREDICTED_STATUS']\n    df_export['PREDICTION_DATE'] = df_new['PREDICTION_DATE']\n    \n\n    # 4️⃣ Save results back to Snowflake\n    session.create_dataframe(df_export).write.mode(\"append\").save_as_table(\"TELCO.DATAMART.TB_R_CHURN_PREDICTION\")\n\n    return f\"Predictions completed for {len(df_new)} records.\"\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4375e37d-0664-42ce-8e74-c974dc1eec11",
   "metadata": {
    "language": "sql",
    "name": "churn_reasoning"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE PROCEDURE TELCO.DATAMART.SP_CHURN_PREDICTION()\nRETURNS STRING\nLANGUAGE SQL\nAS\n$$\nBEGIN\n    CALL TELCO.DATAMART.SP_CUSTOMER_STATUS_PREDICTION();\n\n    CREATE OR REPLACE TABLE TELCO.DATAMART.TB_F_CHURN_PREDICTION AS\n    SELECT DISTINCT\n        a.CUSTOMER_ID,\n        a.PREDICTION_RESULTS,\n        CASE \n            WHEN a.PREDICTION_RESULTS = 'No' THEN NULL\n            ELSE SNOWFLAKE.CORTEX.COMPLETE(\n                'snowflake-arctic',\n                CONCAT(\n                    'You are a churn prediction analyst. ',\n                    'Given this customer profile, explain briefly (in 5–10 words) why this customer might churn: ',\n                    'Gender: ', b.GENDER, ', ',\n                    'Senior Citizen: ', b.SENIOR_CITIZEN, ', ',\n                    'Partner: ', b.PARTNER, ', ',\n                    'Dependents: ', b.DEPENDENTS, ', ',\n                    'Country: ', b.COUNTRY_CODE, ', ',\n                    'State: ', b.STATE, ', ',\n                    'City: ', b.CITY, ', ',\n                    'Latitude: ', b.LATITUDE, ', Longitude: ', b.LONGITUDE, ', ',\n                    'Phone Service: ', c.PHONE_SERVICE, ', ',\n                    'Multiple Lines: ', c.MULTIPLE_LINES, ', ',\n                    'Internet Service: ', c.INTERNET_SERVICE, ', ',\n                    'Online Security: ', c.ONLINE_SECURITY, ', ',\n                    'Online Backup: ', c.ONLINE_BACKUP, ', ',\n                    'Device Protection: ', c.DEVICE_PROTECTION, ', ',\n                    'Tech Support: ', c.TECH_SUPPORT, ', ',\n                    'Streaming TV: ', c.STREAMING_TV, ', ',\n                    'Streaming Movies: ', c.STREAMING_MOVIES, ', ',\n                    'Contract: ', c.CONTRACT_TYPE, ', ',\n                    'Paperless Billing: ', c.PAPERLESS_BILLING, ', ',\n                    'Payment Method: ', c.PAYMENT_METHOD, ', ',\n                    'Date Joined: ', d.DATE_JOINED, ', ',\n                    'Quarter: ', CONCAT('Q', f.quarter, '-', f.year), ', ',\n                    'Tenure (months): ', d.TENURE_MONTHS, ', ',\n                    'Monthly Charges: ', d.MONTHLY_CHARGES, ', ',\n                    'Total Charges: ', d.TOTAL_CHARGES, ', ',\n                    'CLTV: ', d.CLTV, ', ',\n                    'Birth Date: ', b.BIRTH_DATE, ', ',\n                    'Predicted churn status: ', a.PREDICTION_RESULTS, '.'\n                )\n            )\n        END AS CHURN_REASON,\n        a.PREDICTION_DATE\n    FROM TELCO.DATAMART.TB_R_CHURN_PREDICTION a\n    LEFT JOIN TELCO.DATAMART.TB_R_CUSTOMER b ON a.customer_id = b.customer_id\n    LEFT JOIN TELCO.DATAMART.TB_F_SERVICE_USAGE c ON a.customer_id = c.customer_id\n    LEFT JOIN TELCO.DATAMART.TB_F_REVENUE d ON a.customer_id = d.customer_id\n    LEFT JOIN TELCO.DATAMART.TB_R_DATE f ON d.date_joined = f.date_id;\n\n    RETURN '✅ Churn prediction table created successfully with DISTINCT records.';\nEND;\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "957e3563-5dda-4df4-b330-55fd9382bd6b",
   "metadata": {
    "language": "sql",
    "name": "testing"
   },
   "outputs": [],
   "source": "-- SELECT \n--     a.CUSTOMER_ID\n--     ,a.PREDICTION_RESULTS\n--     ,CASE \n--         WHEN a.PREDICTION_RESULTS = 'No' THEN NULL\n--         ELSE SNOWFLAKE.CORTEX.COMPLETE(\n--             'snowflake-arctic',\n--             CONCAT(\n--                 'You are a churn prediction analyst. ',\n--                 'Given this customer profile, explain briefly (in 5–10 words) why this customer might churn: ',\n--                 'Gender: ', b.GENDER, ', ',\n--                 'Senior Citizen: ', b.SENIOR_CITIZEN, ', ',\n--                 'Partner: ', b.PARTNER, ', ',\n--                 'Dependents: ', b.DEPENDENTS, ', ',\n--                 'Country: ', b.COUNTRY_CODE, ', ',\n--                 'State: ', b.STATE, ', ',\n--                 'City: ', b.CITY, ', ',\n--                 'Latitude: ', b.LATITUDE, ', Longitude: ', b.LONGITUDE, ', ',\n--                 'Phone Service: ', c.PHONE_SERVICE, ', ',\n--                 'Multiple Lines: ', c.MULTIPLE_LINES, ', ',\n--                 'Internet Service: ', c.INTERNET_SERVICE, ', ',\n--                 'Online Security: ', c.ONLINE_SECURITY, ', ',\n--                 'Online Backup: ', c.ONLINE_BACKUP, ', ',\n--                 'Device Protection: ', c.DEVICE_PROTECTION, ', ',\n--                 'Tech Support: ', c.TECH_SUPPORT, ', ',\n--                 'Streaming TV: ', c.STREAMING_TV, ', ',\n--                 'Streaming Movies: ', c.STREAMING_MOVIES, ', ',\n--                 'Contract: ', c.CONTRACT_TYPE, ', ',\n--                 'Paperless Billing: ', c.PAPERLESS_BILLING, ', ',\n--                 'Payment Method: ', c.PAYMENT_METHOD, ', ',\n--                 'Date Joined: ', d.DATE_JOINED, ', ',\n--                 'Quarter: ', CONCAT('Q', f.quarter, '-', f.year), ', ',\n--                 'Tenure (months): ', d.TENURE_MONTHS, ', ',\n--                 'Monthly Charges: ', d.MONTHLY_CHARGES, ', ',\n--                 'Total Charges: ', d.TOTAL_CHARGES, ', ',\n--                 'CLTV: ', d.CLTV, ', ',\n--                 'Birth Date: ', b.BIRTH_DATE, ', ',\n--                 'Predicted churn status: ', a.PREDICTION_RESULTS, '.'\n--             )\n--         )\n--     END AS CHURN_REASON\n--     ,a.PREDICTION_DATE\n-- FROM TELCO.DATAMART.TB_R_CHURN_PREDICTION a\n-- LEFT JOIN TELCO.DATAMART.TB_R_CUSTOMER b ON a.customer_id = b.customer_id\n-- LEFT JOIN TELCO.DATAMART.TB_F_SERVICE_USAGE c ON a.customer_id = c.customer_id\n-- LEFT JOIN TELCO.DATAMART.TB_F_REVENUE d ON a.customer_id = d.customer_id\n-- LEFT JOIN TELCO.DATAMART.TB_R_DATE f ON d.date_joined = f.date_id",
   "execution_count": null
  }
 ]
}